{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b662d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1228c62d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import pyvene as pv\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Set a random seed so later our outputs dont keep changing\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9255cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyvene import IntervenableModel\n",
    "\n",
    "# get tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load gpt-2\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "model.eval() \n",
    "\n",
    "# wrap it in pyvene so we can analyze it later\n",
    "empty_config = {}\n",
    "pv_model = IntervenableModel(empty_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87cae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts for subject verb agreement:\n",
      "  'The cat' → should prefer ' is'\n",
      "  'The cats' → should prefer ' are'\n",
      "  'The boy' → should prefer ' is'\n",
      "  'The boys' → should prefer ' are'\n",
      "  'The dog' → should prefer ' is'\n",
      "  'The dogs' → should prefer ' are'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "i want to investigate which neurons are responsible for subject verb agreement\n",
    "so just adding in some simple test cases for that here. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "agreement_sentences = [\n",
    "    (\"The cat\", \" is\"),\n",
    "    (\"The cats\", \" are\"),\n",
    "    (\"The boy\", \" is\"),\n",
    "    (\"The boys\", \" are\"),\n",
    "    (\"The dog\", \" is\"),\n",
    "    (\"The dogs\", \" are\")\n",
    "]\n",
    "\n",
    "print(\"Prompts for subject verb agreement:\")\n",
    "for prompt, correct in agreement_sentences:\n",
    "    print(f\"  {prompt!r} → should prefer {correct!r}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
